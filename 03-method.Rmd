# Probabilidade e Estatística

::: {.theorem name="Teorema da Probabilidade Total"}
Dado um espaço amostral $\Omega$ particionado em $E_1,E_2,...,E_n$ e um evento $A\in \Omega$, a probabilidade de ocorrência de A pode ser expressa por:
$$P(A)=P(A|E_1)\cdot P(E_1)+P(A|E_2)\cdot P(E_2)+...+P(A|E_n)\cdot P(E_n)$$
$$P(A) = \sum\limits_{i=1}^{n} {P(A|E_i)\cdot P(E_i)}$$
:::

---

<br>

::: {.theorem name="Teorema da Bayes"}
Dado um espaço amostral $\Omega$ particionado em $E_1,E_2,...,E_n$ e um evento $A\in \Omega$, a probabilidade condicional de $E_j$ dado $A$, para todo $j\in \{1,2,...,n\}$, é dada por:
$$P(E_j|A) = \frac{P(A|E_j)\cdot P(E_j)}{\sum\limits_{i=1}^{n} {P(A|E_i)\cdot P(E_i)}}$$
:::

---

<br>

## Distribuções de Probabilidade

> $\text{Bernoulli}(p):$ 
> Distribuição associada a um único experimento aleatório com apenas dois resultados possíveis: $0$, caso se observe $A$; e $1$, caso se observe $A^c$.
> Seja $X=$ número de sucessos (espaço amostral finito), então temos que:

$$f(x)=P(X=x)=\begin{cases} 1-p,&\quad x=0,\\ p,&\quad x=1.\end{cases}$$

<br>

> $\text{Binomial}(n, p):$ 
> Distribuição associada a $n$ experimentos aleatórios independentes de Bernoulli.
> Seja $X=$ número de sucessos, a função massa de probabilidade é dada por:

$$f(x)=P(X=x)= \quad {n\choose x}\cdot p^{x}\cdot (1-p)^{n-x}, \qquad x=0,1,...,n$$

> $\text{Poisson}(\lambda):$ 
> Distribuição associada ao número de ocorrências do evento de interesse em um determinado período de tempo.
> Seja $X=$ número de sucessos, a função massa de probabilidade é dada por:

$$f(x)=P(X=x)= \quad \frac{e^{-\lambda}\cdot \lambda^{x}}{x!}, \qquad x=0,1,2,3,...$$

We describe our methods in this chapter.

Math can be added in body using usual syntax like this 

## Lei dos Grandes Números
Em Teoria de Probabilidade, a Lei dos Grandes Números descreve que o resultado ao realizar o mesmo experimento um grande número de vezes.
De acordo com a lei, a média dos resultados obtidos em um grande número de tentativas deve estar próxima do valor esperado, e tende a se aproximar mais, à medida que mais tentativas são realizadas.
Seja $X_1, X_2, ..., X_N$ uma sequência de variáveis aleatórias independentes de uma mesma distribuição de probabilidade. Seja $E(X_i) = \mu$. Então, com probabilidade 1, temos que:

$$
\frac{X_1 + X_2 + X_3 + \cdots + X_n}{n} \rightarrow \mu \quad \quad \quad \text{as} \quad n \rightarrow \infty
$$

Para ilustrar o teorema acima, suponha que, a probabilidade de conclusão de um curso, em cada turma de 30 alunos, seja $p = 0.7$. Uma turma selecioanda aleatoriamente, possui o seguinte número de formandos:
```{r, echo=FALSE, message=F}
library(dplyr)
library(ggplot2)
```

```{r, comment="", eval=FALSE}
turma_1 <- rbinom(n = 30, size = 1, prob = 0.7)
sum(turma_1)
# [1] 22
mean(turma_1)
# [1] 0.7333333
```
Imagine agora, que coletamos a mesma informação, para 100 turmas.
```{r, comment=""}
n_turmas <- vector(mode = "list", length = 100)

for (i in seq_along(n_turmas)){
    n_turmas[[i]] <- rbinom(n = 30, size = 1, prob = 0.7)
}
```

Vamos olhar a média das três primeiras turmas:
```{r, comment="", eval=FALSE}
n_turmas[[1]] %>% mean()
# [1] 0.7333333
n_turmas[[2]] %>% mean()
# [1] 0.7333333
n_turmas[[3]] %>% mean()
# [1] 0.7666667
```

Mas se juntarmos, todos os alunos, em uma única gigantesca turma, temos a seguinte proporção de formandos:
```{r, comment="", eval=FALSE}
n_turmas %>% unlist() %>% mean()
# [1] 0.697
```

## Teorema do Limite Central

Seja $X_1, X_2, ..., X_N$ uma sequência de variáveis aleatórias independentes e identicamente distribuídas (i.i.d), com média $\mu$ e variância $\sigma^2$.
A distribuição de 

$$
\frac{X_1 + X_2 + X_3 + \cdots + X_n - n\mu}{\sigma \sqrt{n}} \rightarrow Z \sim N(0,1) \quad \quad \quad \text{as} \quad n \rightarrow \infty
$$

Então temos que:
$$
\frac{\bar{X} - \mu}{ \frac{\sigma}{\sqrt{n}} } \rightarrow Z \sim N(0,1) \quad \quad \quad \text{as} \quad n \rightarrow \infty
$$

Em outras palavras, o Teorema do Limite Central garante que, para grandes amostras, a média amostral padronizada segue uma distribuição normal com média 0 e variância 1.
<!-- You can also use math in footnotes like this^[where we mention $p = \frac{a}{b}$]. -->

<!-- We will approximate standard error to 0.027[^longnote] -->

<!-- [^longnote]: $p$ is unknown but expected to be around 1/3. Standard error will be approximated -->

[{"path":"index.html","id":"about","chapter":"1 About","heading":"1 About","text":"Authors: Cayan Portela Herbet Kimura.University Brasília, Mangement Department.material constant development used show fundamental concepts data science.Subjects:\nProbability Statistics.\nQuantitative Finance.\nProbability Statistics.Quantitative Finance.","code":""},{"path":"intro.html","id":"intro","chapter":"2 Introduction","heading":"2 Introduction","text":"Muitas vezes, é de nosso interesse comparar parâmetros entre grupos.Creating sequence dates. Simulated values regarded weekly period time.Simulating data-set poisson negative binomial distributions.\n(explicar parametros e o que os valores da tabela significam. abc)Table 2.1: Simulated valuesExplaining difference distributions.\nNow going use values simulate \\(n\\) observations continuous distribution sum .\nsimulated severity loss.\nGamma, Log-normal Weibull.Customized function.Severity values frquency genreated poisson distributionReference figure code chunk label fig: prefix, e.g., Similarly, can reference tables generated knitr::kable(), e.g., see Table 2.1.can write citations, . example, using bookdown package (Xie 2023) sample book, built top R Markdown knitr (Xie 2015).","code":"\nlibrary(tidyverse)\n# sequence of dates (weekly)\ndate_seq <- seq.Date(from = as.Date(\"2022-01-01\"),\n                     to = as.Date(\"2022-06-30\"),\n                     by = \"week\")\n# number of weeks\nn_week <- length(date_seq)\nsim_data <- data.frame(\n  week = date_seq,\n  poisson = rpois(n = n_week, lambda = 15),\n  neg_bin = rnbinom(n = n_week, mu = 10, size = 4)\n)\n\nknitr::kable(\n  head(sim_data, 10), caption = \"Simulated values\",\n  booktabs = TRUE)\nseveridade <- function(n_dist, dist, pars) {\n\n  random_function <- switch(dist,\n    gamma     = \"rgamma\",\n    lognormal = \"rlnorm\",\n    weibull   = \"rweibull\",\n    stop(\"Invalid distribution\")\n  )\n\n  parameters <- c(\"n\" = n_dist, pars)\n  values <- do.call(what = random_function, args = parameters)\n\n  return(sum(values))\n}\nsev_pois <- sim_data %>%\n  select(week, poisson) %>%\n  dplyr::rowwise() %>%\n  mutate(\n    # gamma\n    gamma = severidade(\n      n_dist = poisson, dist = \"gamma\",\n      pars = list(\"shape\" = 6, \"rate\" = 0.0006)\n    ),\n    # log-normal\n    lnorm = severidade(\n      n_dist = poisson, dist = \"lognormal\",\n      pars = list(\"meanlog\" = 9, \"sdlog\" = 0.4)\n    ),\n    # weibull\n    weib = severidade(\n      n_dist = poisson, dist = \"weibull\",\n      pars = list(\"shape\" = 2.75, \"scale\" = 12000)\n    )\n  )"},{"path":"literature.html","id":"literature","chapter":"3 Literature","heading":"3 Literature","text":"review existing methods.","code":""},{"path":"methods.html","id":"methods","chapter":"4 Methods","heading":"4 Methods","text":"describe methods chapter.Math can added body using usual syntax like ","code":""},{"path":"methods.html","id":"lei-dos-grandes-números","chapter":"4 Methods","heading":"4.1 Lei dos Grandes Números","text":"Em Teoria de Probabilidade, Lei dos Grandes Números descreve que o resultado ao realizar o mesmo experimento um grande número de vezes.\nDe acordo com lei, média dos resultados obtidos em um grande número de tentativas deve estar próxima valor esperado, e tende se aproximar mais, à medida que mais tentativas são realizadas.\nSeja \\(X_1, X_2, ..., X_N\\) uma sequência de variáveis aleatórias independentes de uma mesma distribuição de probabilidade. Seja \\(E(X_i) = \\mu\\). Então, com probabilidade 1, temos que:\\[\n\\frac{X_1 + X_2 + X_3 + \\cdots + X_n}{n} \\rightarrow \\mu \\quad \\quad \\quad \\text{} \\quad n \\rightarrow \\infty\n\\]Para ilustrar o teorema acima, suponha que, probabilidade de conclusão de um curso, em cada turma de 30 alunos, seja \\(p = 0.7\\). Uma turma selecioanda aleatoriamente, possui o seguinte número de formandos:Imagine agora, que coletamos mesma informação, para 100 turmas.Vamos olhar média das três primeiras turmas:Mas se juntarmos, todos os alunos, em uma única gigantesca turma, temos seguinte proporção de formandos:","code":"\nturma_1 <- rbinom(n = 30, size = 1, prob = 0.7)\nsum(turma_1)[1] 22\nmean(turma_1)[1] 0.7333333\nn_turmas <- vector(mode = \"list\", length = 100)\n\nfor (i in seq_along(n_turmas)){\n    n_turmas[[i]] <- rbinom(n = 30, size = 1, prob = 0.7)\n}\nn_turmas[[1]] %>% mean()[1] 0.6333333\nn_turmas[[2]] %>% mean()[1] 0.7666667\nn_turmas[[3]] %>% mean()[1] 0.7666667\nn_turmas %>% unlist() %>% mean()[1] 0.7016667"},{"path":"methods.html","id":"teorema-do-limite-central","chapter":"4 Methods","heading":"4.2 Teorema do Limite Central","text":"Seja \\(X_1, X_2, ..., X_N\\) uma sequência de variáveis aleatórias independentes e identicamente distribuídas (..d), com média \\(\\mu\\) e variância \\(\\sigma^2\\).\ndistribuição de\\[\n\\frac{X_1 + X_2 + X_3 + \\cdots + X_n - n\\mu}{\\sigma \\sqrt{n}} \\rightarrow Z \\sim N(0,1) \\quad \\quad \\quad \\text{} \\quad n \\rightarrow \\infty\n\\]Então temos que:\n\\[\n\\frac{\\bar{X} - \\mu}{ \\frac{\\sigma}{\\sqrt{n}} } \\rightarrow Z \\sim N(0,1) \\quad \\quad \\quad \\text{} \\quad n \\rightarrow \\infty\n\\]Em outras palavras, o Teorema Limite Central garante que, para grandes amostras, média amostral padronizada segue uma distribuição normal com média 0 e variância 1.\n","code":""},{"path":"teste-de-hipóteses.html","id":"teste-de-hipóteses","chapter":"5 Teste de Hipóteses","heading":"5 Teste de Hipóteses","text":"Em situações em que estamos interessados em testar afirmações sobre determinado parâmetro desconhecido. O parâmetro representa uma medida de interesse estudo, levando à formulação de uma hipótese.\nCom hipótese formulada, utilizamos metodologias estatísticas para nos auxiliar em tomadas de decisões.","code":""},{"path":"teste-de-hipóteses.html","id":"alguns-conceitos","chapter":"5 Teste de Hipóteses","heading":"5.1 Alguns Conceitos","text":"População: conjunto de observações de interesse. Em geral, não temos acesso à todos os elementos da população. (recursos escassos ou população infinita)Dessa maneira, o conhecimento adquirido em relação à população de interesse é feito exaimando apenas alguns elementos da população.Amostra Aleatória Simples (..S.): Nesse tipo de amostragem, cada elemento tem mesma probabilidade de ser incluído na amostra.Ao selecionar uma amostra aleatória de tamanho \\(n\\), obtemos um vetor aleatório \\((x_1, x_2, ..., x_n)\\). Com o vetor aleatória, podemos calcular média amostral \\(\\bar{x}\\).\nmédia amostral \\(\\bar{x}\\) também é uma variável aleatória, pois seu valor varia de amostra para amostra. medidas geradas por valores amostrais são estatísticas.Parâmetro: Medida de uma característic da população (não é uma v..). Em geral, representada por \\(\\theta\\).Estatística: Característica associada aos dados de uma amostra. É uma função das variáveis aleatórias que constituem uma amostra. É portanto, uma variável aelatória.Estimador: É uma estatística construída com finalidade de representar, ou estimar, o parâmetro de interesse na população. estimativas são os valores numéricos assumidos pelos estimadores, usualmente denotados por \\(\\hat{\\theta}\\).","code":""},{"path":"teste-de-hipóteses.html","id":"análise-de-experimentos","chapter":"5 Teste de Hipóteses","heading":"5.2 Análise de Experimentos","text":"Em experimentos, nos referimos à investigações em que o pesquisador possuir controle sob condições de interesse, tornando viável inferência sobre relações de causa e efeito.\nPode-se definir experimento como um série de rodadas em que mudanças propositais são realizadas nas variáveis de input para poder verificar possíveis alterações na variávei resposta (Montgomery, 2013).Tratamentos: “intervenções” de interesse.Tratamentos: “intervenções” de interesse.Unidades experimentais: menor subdivisão experimento que o tratamento é atribuído.Unidades experimentais: menor subdivisão experimento que o tratamento é atribuído.Respostas: medida de interesse observada na unidade experimental.Respostas: medida de interesse observada na unidade experimental.Príncipios da Análise de Experimentos.\nRandomização\nReplicação\nBlocagem\nPríncipios da Análise de Experimentos.RandomizaçãoReplicaçãoBlocagemRandomização corresponde à aleatoriedade na alocação de tratamentos em unidades experimentaise nas rodadas experimento. Em geral, isso valida os pressupostos de independência de métodos estatísticos.Replicação corresponde à rodadas independentes em cada combinação de tratamentos/fatores. Permite obter uma estimativa erro experimental, consequentemente dos parâmetros (importante na comparação entre tratamentos).Blocagem é utilizado para reduzir variabilidade relativa à ruídos; fatores que podem influenciar resposta observada na unidade exeprimental, mas em que não temos interesse direto.","code":""},{"path":"teste-de-hipóteses.html","id":"experimentos-completamente-randomizados","chapter":"5 Teste de Hipóteses","heading":"5.3 Experimentos completamente randomizados","text":"idéia de experimentos completamente randomizados é que escolha tratamento ser atribuído para \\(\\)-ésima observação seja aleatória.Por exemplo, caso deseja-se realizar um experimento que compare duas marcas de fertilizantes “” e “B”, referente ao crescimento das plantas. Nesse caso, imagine que temos 10 plantas, dispostas em um mesmo terreno, plantadas em um mesmo determinado tempo, sob mesmas condições:Queremos então, que os tratamentos “” e “B” (referntes aos fertilizantes), sejam atribuídos aleatoriamente às plantas.Digamos então, que o experimento foi realizado, e os seguintes valores referentes ao crescimento da planta (em cm), foram observados:Observando o box-plot abaixo, o tratamento “” parece ter fornecido um maior impulsionamento crescimento das plantas, em relação ao tratamento “B”.Vamos osbervar então, como foi diferença das médias entre tratamentos:Porém, supondo não haver diferença entre os tratamentos, e que ambos tenham mesma distribuição, o quão “raro” seria observar exatamente essa diferença?O número de combinações possíveis é de \\({10\\choose 5} = 252\\)Dentre todas combinações possíveis, podemos analisar distirbuição de diferenças de médias, considerando os dados observados.partir daí, podemos ter ideia de que, dado suposição de que não há diferença entre médias, o resultado observado é um tanto quanto raro. Com esse conceito, temos então, indícios de que suposição de igualdade entre distribuições das médias não seja o que de fato ocorre.Assumindo independência entre observações, temos que observações possuem mesma probabilidade de receber certo tratamento. Então, probabilidade de observamos um valor maior ou tão extremo quanto o observado, é dada por:\\[ P( X \\ge x | H_0) = \\sum_{=1}^{N\\choose k} \\frac{(x_i \\le x*)}{N\\choose k}\\]exemplo, podemos calcular:E caso bilateral:E se ao invés de cinco replicações por tratamento, tivéssemos 10?E se fossem 20?O número de combinações torna-se muito grande \\({20\\choose 10} = 184756\\)Por outro lado, se tivéssemos apenas duas replicações, o número de combinações seria de apenas 6.Assim, replicação permite uma maior robustez quanto à estimativa da possível variabilidade presente fenômeno. Como em algum certo ponto é inviável simularmos todas possíveis ocorrências fenômeno, recorremos à distribuições de probabilidade que modelam o processo gerador de dados.Para comparar média dos dois tratamentos, podemos utilizar o teste-t para variâncias iguais.Que é equivalente ao resultado da anova, pois \\(t_v^2 = F_{1,v}\\).Mas o que representam esses resultados?Para avaliar diferença entre média de dois ou mais tratmentos, podemos utilizar análise de variância (ANOVA).","code":"\ntrat1 <- rep(c(\"A\", \"B\"), each = 5)\ntrat1 [1] \"A\" \"A\" \"A\" \"A\" \"A\" \"B\" \"B\" \"B\" \"B\" \"B\"\nset.seed(123)\nsample(trat1, 10) [1] \"A\" \"B\" \"A\" \"B\" \"B\" \"B\" \"A\" \"B\" \"A\" \"A\"\nset.seed(123)\ndf_planta <- tibble(planta = paste0(\"P\", 1:10),\n                    trat   = sample(trat1, 10))\n\ndf_planta# A tibble: 10 × 2\n   planta trat \n   <chr>  <chr>\n 1 P1     A    \n 2 P2     B    \n 3 P3     A    \n 4 P4     B    \n 5 P5     B    \n 6 P6     B    \n 7 P7     A    \n 8 P8     B    \n 9 P9     A    \n10 P10    A    \ndf_planta <- df_planta %>%\n  mutate(y_cm = c(14.22, 5.59, 15.41, 10.34, 9.73,\n                  12.32, 16.15, 10.80, 15.29, 12.44 ) )\n\ndf_planta# A tibble: 10 × 3\n   planta trat   y_cm\n   <chr>  <chr> <dbl>\n 1 P1     A     14.2 \n 2 P2     B      5.59\n 3 P3     A     15.4 \n 4 P4     B     10.3 \n 5 P5     B      9.73\n 6 P6     B     12.3 \n 7 P7     A     16.2 \n 8 P8     B     10.8 \n 9 P9     A     15.3 \n10 P10    A     12.4 \ntapply(df_planta$y_cm, df_planta$trat, mean)     A      B \n14.702  9.756 \nggplot(df_planta, \n       aes(x = trat, y = y_cm, fill = trat)) +\n  geom_boxplot()\n  df_planta %>%\n    group_by(trat) %>%\n    summarise(media = mean(y_cm)) %>%\n    .$media %>%\n    dist()      1\n2 4.946\nchoose(10, 5)[1] 252\ny1 <- df_planta$y_cm\n\nmedias <- combn(y1, m = 5)\n\nN = choose(10, 5)\ndif_media <- rep(NA, N)\n\n  for(i in 1:N) {\n    dif_media[i] <- mean(medias[,i]) - mean(setdiff(y1, medias[,i]))   \n  }\np1 <- ggplot() +\n    geom_histogram(aes(dif_media),\n                   fill = \"cyan4\",\n                   col = \"white\",\n                   bins = 30) +\n    geom_vline(xintercept = c(quantile(dif_media, 0.025),\n                              quantile(dif_media, 0.975)),\n               col = \"firebrick\",\n               linetype = \"dashed\") +\n    geom_point(x = 4.946, y = 0, size = 1.5, col = \"purple\") +\n    theme_minimal()\np1\nsum(dif_media >= 4.946) / N[1] 0.003968254\n2*sum(dif_media >= 4.946) / N[1] 0.007936508Error: não é possível alocar vetor de tamanho 63.2 Gb\nt.test(df_planta$y_cm[df_planta$trat == \"A\"],\n       df_planta$y_cm[df_planta$trat == \"B\"],\n       var.equal = TRUE)\n    Two Sample t-test\n\ndata:  df_planta$y_cm[df_planta$trat == \"A\"] and df_planta$y_cm[df_planta$trat == \"B\"]\nt = 3.8129, df = 8, p-value = 0.005142\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 1.954676 7.937324\nsample estimates:\nmean of x mean of y \n   14.702     9.756 \naov(y_cm ~ trat, data = df_planta) %>%\n  summary()            Df Sum Sq Mean Sq F value  Pr(>F)   \ntrat         1  61.16   61.16   14.54 0.00514 **\nResiduals    8  33.65    4.21                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n3.8129^2[1] 14.53821"},{"path":"teste-de-hipóteses.html","id":"análise-de-variância-para-um-fator","chapter":"5 Teste de Hipóteses","heading":"5.4 Análise de Variância para um fator","text":"Análise de variância (ANOVA) é um modelo linear, pois variável resposta é modelada como uma função linear dos parâmetros. Utilizado para análise entre grupos e dentre grupos, o modelo realiza contrastes entre classes, resultando na comparação entre médias de tratamentos.\\[\n\\begin{aligned}\n\\text{H}_0 &: \\ \\mu_1 = \\mu_2 = \\cdots = \\mu_k \\\\\n\\text{H}_1 &: \\ \\mu_i \\ne \\mu_j \\ \\text{para algum par}\\  \\ ,j \n\\end{aligned}\n\\]Pressupostos\nAmostras independentes\nNormalidade dos resíduos\nHomocedasticidade\nSensível outliers\nAmostras independentesNormalidade dos resíduosHomocedasticidadeSensível outliers“O interrogatório habilidoso da natureza”: O experimento de Fisher\"\nTeste F\nComparaçã de médias: Teste de Tukey\nTeste FComparaçã de médias: Teste de TukeyUm conjunto de procedimentos que têm como base comparação entre variâncias com o propósito de verificar em que medida diferenças nas médias de respostas de grupos diferentes são estatisticamente significativas (Tabachnick & Fidell, 2019).especificação modelo é dada por:\\[y_{ij} = \\mu + \\tau_i + \\epsilon_{ij}\\]\nem que \\(\\mu\\) representa média geral, \\(\\tau_i\\) representa o \\(\\)-ésimo efeito de tratamento e \\(\\epsilon_{ij}\\) representa o erro aleatório.","code":"\nsimula <- function(mu, t1, t2, sigma, n) {\n  \n  y1 <- mu + t1 + rnorm(n, 0, sigma)\n  y2 <- mu + t2 + rnorm(n, 0, sigma)\n  y3 <- mu + rnorm(n, 0, sigma)\n  \n  yy <- c(y1, y2, y3)\n  \n  trat <- as.factor( c(rep(LETTERS[1], n), rep(LETTERS[2], n), rep(LETTERS[3], n)) )\n  \n  df <- data.frame(y = yy,\n                   trat = trat)\n  \n  return(list(dados = df))\n  \n}\nset.seed(123)\nsim_df <- simula(mu = 10, t1 = 5, t2 = -5, sigma = 5, n = 10)\ncar::leveneTest(y ~ trat, data = sim_df$dados)Levene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(>F)\ngroup  2   5e-04 0.9995\n      27               \nmod <- aov(y ~ trat, data = sim_df$dados)\nsummary(mod)            Df Sum Sq Mean Sq F value   Pr(>F)    \ntrat         2  488.7  244.34   10.27 0.000481 ***\nResiduals   27  642.1   23.78                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nshapiro.test(mod$residuals)## \n##  Shapiro-Wilk normality test\n## \n## data:  mod$residuals\n## W = 0.96213, p-value = 0.3507\nTukeyHSD(mod)  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = y ~ trat, data = sim_df$dados)\n\n$trat\n         diff        lwr       upr     p adj\nB-A -9.330018 -14.737296 -3.922740 0.0006008\nC-A -7.495923 -12.903201 -2.088645 0.0052775\nC-B  1.834096  -3.573182  7.241374 0.6812485\nplot(TukeyHSD(mod, conf.level = 0.95),las=1, col = \"red\")"},{"path":"teste-de-hipóteses.html","id":"experimentos-randomizados-blocados","chapter":"5 Teste de Hipóteses","heading":"5.5 Experimentos Randomizados Blocados","text":"Experimentos com bloco ocorrem quando há um fator conhecido e controlável, que pode ser responsável por algum tipo de intervenção na resposta.Imagine exemplo anterior sobre plantas. Mas temos 3 fertilizantes, e metade das plantas estão em uma estufa e outra metade céu aberto. Talvez, esse fator possa exercer alguma influência nas médias observadas. Assim, adicionamos um fator de controle.\\[y_{ijk} = \\mu + \\beta_j + \\tau_i + \\epsilon_{ijk}\\]em que \\(\\beta_j\\) representa área (estufa ou céu aberto). Assim, teríamos três tratamentos e dois blocos.","code":"\nmod2 <- aov(y ~ bloco + trat, data = df_planta2)\ndata.frame(y = df_planta2$y, model.matrix(mod2) ) %>%\n  slice(c(1:5, 20:25, 40:45))           y X.Intercept. blocoE tratB tratC\n1  11.796529            1      0     0     0\n2  14.346075            1      0     0     0\n3  11.921987            1      0     0     0\n4  12.813326            1      0     0     0\n5  13.124882            1      0     0     0\n20 13.858587            1      0     0     0\n21  7.915879            1      0     1     0\n22  9.376248            1      0     1     0\n23  6.203811            1      0     1     0\n24 16.506868            1      0     1     0\n25 13.623886            1      0     1     0\n40 10.647825            1      1     1     0\n41  6.279393            1      1     0     1\n42  4.114786            1      1     0     1\n43  7.685377            1      1     0     1\n44  7.634400            1      1     0     1\n45  7.464743            1      1     0     1"},{"path":"teste-de-hipóteses.html","id":"experimentos-fatoriais","chapter":"5 Teste de Hipóteses","heading":"5.6 Experimentos Fatoriais","text":"Um experimento completamente randomizado com dois fatores, pode ser representado por:\\[y_{ijk} = \\mu_{ij} + \\epsilon_{ijk}\\]\nem que \\(\\) e \\(j\\) representam os níveis primeiro e segundo fator, respectivamente, e \\(k\\) denota \\(k\\)-ésima replicação. O modelo também pode ser escrito utilizando representação dos efeitos, como:\\[y_{ijk} = \\mu + \\alpha_i + \\tau_j + \\alpha\\tau_{ij} + \\epsilon_{ijk}\\]\nem que \\(alpha_i\\) e \\(beta_j\\) representam diferença marginal da média total entre os experimentos, \\(\\)-ésimo nível primeiro fator e \\(j\\)-ésimo nível segundo fator. interação \\(\\alpha\\beta_{ij}\\) representa diferença entre o valor principal e os efeitos marginais isolados.","code":""},{"path":"teste-de-hipóteses.html","id":"outros-modelos","chapter":"5 Teste de Hipóteses","heading":"5.7 Outros Modelos","text":"Repostas não-gaussianas.Repostas não-gaussianas.Quadrados Latinos.Quadrados Latinos.Confundimento.Confundimento.Medidas repetidas.Medidas repetidas.","code":""},{"path":"otimização.html","id":"otimização","chapter":"6 Otimização","heading":"6 Otimização","text":"","code":""},{"path":"otimização.html","id":"estatística-e-machine-learning","chapter":"6 Otimização","heading":"6.1 Estatística e Machine Learning","text":"abordagem estatística para análise e resumo de informações contidas em um conjunto de dados, consiste na suposição de que existe um mecanismo estocástico gerador processo em análise (Bonat et al. 2012). Para isso, existem técnica que nos auxiliam na estimação de uma função (e.g. de regressão) que são de fundamental importância em estatística e machine learning.Muitas ténicas de regressão usadas hoje são datadas de muitos anos atrás. Todavia, com o avanço computacional, métodos mais robustos em relação ao real processo gerador vêm ganhando cada vez mais espaço e importância(Izbicki Santos 2020). Por exemplo, em modelos com mais covariáveis que observações, métodos tradicionais sofrem pela falta de graus de liberdade.De maneira geral, nosso objetivo é determinar uma relação entre uma variável aleatória de interesse \\(Y\\) e um vetor de covariáveis \\(x = (x_1, ..., x_n)\\). Então, temos que:\\[ g(x) := E [ Y | X = x]\\]Material de otimização numérica.","code":""},{"path":"other-considerations.html","id":"other-considerations","chapter":"7 Other Considerations","heading":"7 Other Considerations","text":"like tell something.","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"Bonat, Wagner Hugo, Paulo Justiniano Ribeiro Jr, Elias Teixeira Krainski, Walmes Marques Zeviani. 2012. “Métodos Computacionais Em Inferência Estatı́stica.” SINAPE. Curitiba: Associação Brasileira de Estatı́stica-ABE.Izbicki, Rafael, Tiago Mendonça dos Santos. 2020. Aprendizado de Máquina: Uma Abordagem Estatı́stica. Rafael Izbicki.Xie, Yihui. 2015. Dynamic Documents R Knitr. 2nd ed. Boca Raton, Florida: Chapman; Hall/CRC. http://yihui.name/knitr/.———. 2023. Bookdown: Authoring Books Technical Documents R Markdown. https://CRAN.R-project.org/package=bookdown.","code":""}]
